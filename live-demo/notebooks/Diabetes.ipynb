{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [Pima Indians Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) to develop a simple model predicting onset of diabetes using a few simple features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/diabetes.csv', delimiter=',')\n",
    "print(data.columns.to_list())\n",
    "print(data.head())\n",
    "print(data.groupby('Outcome')['Glucose'].plot.kde())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "Splitting the data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(x, y, test_size, random_state):\n",
    "    x_train, x_test_temp, y_train, y_test_temp = train_test_split(x,y, test_size = 0.5, random_state=42)\n",
    "    x_validate, x_test, y_validate, y_test = train_test_split(x_test_temp, y_test_temp, test_size = 0.5, random_state=42)\n",
    "    return x_train, y_train, x_validate, y_validate, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_validate, y_validate, x_test, y_test = train_validate_test_split(\n",
    "    x = data.drop(columns = 'Outcome'), \n",
    "    y = data['Outcome'], \n",
    "    test_size = .5, \n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperglyemic_flag(series, **kwargs):\n",
    "    return np.where(\n",
    "        series > (kwargs.get('glucose_value') or 240), 1, 0\n",
    "    )\n",
    "\n",
    "def create_hypoglyemic_flag(series, **kwargs):\n",
    "    return np.where(\n",
    "        series < (kwargs.get('glucose_value') or 100), 1, 0\n",
    "    )\n",
    "\n",
    "def generate_features(df):\n",
    "    result = df.copy(deep=True)\n",
    "    result['hyperglycemic_flag'] = create_hyperglyemic_flag(result['Glucose'])\n",
    "    result['hypoglycemic_flag'] = create_hypoglyemic_flag(result['Glucose'])\n",
    "    return result\n",
    "\n",
    "x_train = generate_features(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('svc', SVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate = generate_features(x_validate)\n",
    "y_predict = pipe.predict(x_validate)\n",
    "\n",
    "cm = np.array(confusion_matrix(y_validate, y_predict, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(cm, index=['Not Diabetic', 'Diabetic'], columns=['Predicted Healthy', 'Predicted Diabetes'])\n",
    "\n",
    "display(Markdown('## Confusion matrix'))\n",
    "print(confusion)\n",
    "display(Markdown('<br>'))\n",
    "display(Markdown('## Classification report'))\n",
    "print(classification_report(y_validate, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and related objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = {\n",
    "        'model_pipeline': pipe,\n",
    "        'data_features': x_train.columns.tolist(),\n",
    "        'name': f'Diabetes predictor',\n",
    "        'model_version': '0.0',\n",
    "        'model_type': 'Supervised',\n",
    "        'model_objective': 'Classification',\n",
    "        'model_algorithm': 'Support Vector Classification (SVC)',\n",
    "        'model_trained_date': str(datetime.today().date())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_package, '../models/diabetes_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
